---
title: "Key Factors Influencing Income Level"
author: "Group26: JiaweiDeng QingHan PingchuanMA AoQiao XinWang"
number-sections: true
format:
  pdf: default
  html:
    embed-resources: true
    code-tools: true
editor_options: 
  chunk_output_type: console
execute:
  echo: true
  eval: true
  warning: false
  message: false
geometry: margin=1in,landscape
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \floatplacement{table}{H}
---

# Introductions {#sec-intro}

This study aims to identify the key socioeconomic determinants influencing whether an individual earns more than \$50k annually, utilizing data from the 1994 U.S. Census. The dataset comprises a diverse set of socioeconomic attributes, including age, education level, marital status, occupation, sex, hours worked per week, and nationality. The outcome variable, Income, is a binary classification indicating whether an individual's earnings exceed the \$50k threshold.

To achieve this objective, a Generalized Linear Model (GLM) is employed to examine the relationship between income levels and various socioeconomic predictors. In this framework, income serves as the dependent variable, while the remaining attributes function as independent variables, enabling a systematic evaluation of their respective contributions to income disparity.

# Libraries and reading {#sec-lr}

First, we load all the necessary packages required for the analysis.

```{r}
#| label: libraries
# Load the necessary package
library(ggplot2)
library(glmnet)
library(tidyverse)
library(gt)
library(patchwork)
library(gridExtra)
library(moderndive)
library(skimr)
library(sjPlot)
```

Then we import the CSV file from the specified source.

```{r}
#| label: data
# Read CSV data
data <- read.csv('dataset26.csv', na.strings = '?,')
```

# Initial Model {#sec-mdl1}

## Data Tidying

Initially, we delete the null data, and treat only hours and age as numeric variables.

```{r}
#| label: tidy
data <- na.omit(data)
data <- data %>%
  mutate(across(2:ncol(data), ~ substr(.x, 1, nchar(.x) - 1)))
write.csv(data, 'cleaned_data.csv', row.names = FALSE)
```

```{r}
#| label: trans
data$Income <- ifelse(data$Income == "<=50", 0, 1)
data$Education <- as.factor(data$Education)
data$Marital_Status <- as.factor(data$Marital_Status)
data$Occupation <- as.factor(data$Occupation)
data$Sex <- as.factor(data$Sex)
data$Hours_PW <- as.numeric(data$Hours_PW)
data$Nationality <- as.factor(data$Nationality)

str(data)
```

## Full Modeling

After fitting the model, we observed that the large number of coefficients makes it difficult to identify the most influential variables.

```{r}
#| label: fullmodel
model <- glm(Income ~ Age + Education + Marital_Status + Occupation + Sex + Hours_PW + Nationality, 
             data = data, 
             family = binomial)
summary(model)
```

Therefore, we selected variables with p-values below 0.05 for further analysis.

```{r}
#| label: p-value
coef_table <- summary(model)$coefficients
coef_df <- as.data.frame(coef_table)

significant_vars <- coef_df[coef_df$`Pr(>|z|)` < 0.05, ]
significant_vars
```

As observed, **Age**, **Education**, **Marital Status**, **Occupation**, and **Hours Worked per Week** appear to be the most significant variables in this model.

# Refined Model {#sec-mdl2}

## Data wrangling

Based on the previous p-value selection, we made adjustments to the variables: the education levels were reclassified, converted into a factor variable in ascending order, and then transformed into continuous numerical values. A similar transformation was applied to nationality. Significant job positions were treated as a separate variable, while other positions were consolidated into a general "Other" category to reduce overfitting in the model. A similar approach was applied to marital status.

```{r}
#| label: Data wrangling
# Order education level
edu_levels <- c(
  "Preschool", "1st-4th", "5th-6th", "7th-8th", "9th", "10th", 
  "11th", "12th", "HS-grad", "Some-college", "Assoc-acdm", 
  "Assoc-voc", "Bachelors", "Masters", "Prof-school", "Doctorate"
)
data$Education <- factor(data$Education, levels = edu_levels, ordered = TRUE)
data$Education <- as.numeric(data$Education)

# Order nationality level
data$Nationality <- as.factor(data$Nationality)
data$Nationality <- as.numeric(data$Nationality)

# Merge Occupation
levels(data$Occupation) <- ifelse(levels(data$Occupation) %in% c("Exec-managerial"), 
                                      levels(data$Occupation), "Other")
data$Occupation <- factor(data$Occupation)
data$Occupation <- relevel(data$Occupation, ref = "Other") # Set “Other” as the base group

# Merge Marital Status
levels(data$Marital_Status) <- ifelse(levels(data$Marital_Status) %in% c("Married-civ-spouse"), 
                                      levels(data$Marital_Status), "Other")
data$Marital_Status <- factor(data$Marital_Status)
data$Marital_Status <- relevel(data$Marital_Status, ref = "Other") # Set “Other” as the base group
```

## Data Visualization

```{r}
#| label: Density plot
# Select numerical variables for density plotting.
numeric_vars <- sapply(data, is.numeric)
data_numeric <- data[, numeric_vars]

# Plot the density graph
par(mfrow=c(2,2))  # 2x2 
for (var in names(data_numeric)) {
  plot(density(data_numeric[[var]]), 
       col = "blue", 
       main = paste("Density Plot of", var),
       xlab = var)
}
```

The Density Plots show the distribution of the data, but in GLM, whether the data follows a normal distribution is not a concern for our analysis. Therefore, we only present the distribution of the data here.

Based on the practical context, only age and hours worked are continuous variables in a meaningful sense. Therefore, we only plot the boxplot for these two variables.

```{r}
#| label: Box plot
# Define colors
colors <- c("red", "blue")

# Generate Age vs. Income boxplot
plot_age <- ggplot(data, aes(x = factor(Income), y = Age, fill = factor(Income))) +
  geom_boxplot() +
  scale_fill_manual(values = colors) +
  xlab('Income') + 
  ylab('Age') +
  ggtitle('Age vs. Income Boxplot') +
  theme_minimal()

# Generate Hours per Week vs. Income boxplot
plot_hours <- ggplot(data, aes(x = factor(Income), y = Hours_PW, fill = factor(Income))) +
  geom_boxplot() +
  scale_fill_manual(values = colors) +
  xlab('Income') + 
  ylab('Hours per Week') +
  ggtitle('Hours per Week vs. Income Boxplot') +
  theme_minimal()

# Arrange all boxplots in a grid layout
grid.arrange(plot_age, plot_hours, ncol = 2)
```

From the chart, it can be observed that higher age seems to be helpful for earning \>50K, while the distribution of hours worked is more scattered.

## New Modeling

```{r}
#| label: New model
model_new <- glm(Income ~ Age + Education + Marital_Status + Occupation + Sex + Hours_PW + Nationality, 
             data = data, 
             family = binomial)
summary(model_new)
```

The model is now more concise, and the results of variable selection align with our initial expectations.

# Stepwise {#sec-stp}

```{r}
#| label: Stepwise
stepwise_model <- step(model_new, direction = "both", trace = 0)
summary(stepwise_model)

stepwise_aic <- AIC(stepwise_model)
print(paste("Stepwise AIC: ", stepwise_aic))
```

As can be seen, our new model also performs well under AIC, showing the same selection results as the p-value approach.

# Data Correlation {#sec-dcr}

```{r}
#| label: cor
num_data <- data[, sapply(data, is.numeric)]
cor_matrix <- cor(num_data)
print(cor_matrix)

data_encoded <- model.matrix(~ Marital_Status + Occupation + Sex- 1, data = data)
cor_matrix_encoded <- cor(data_encoded)
print(cor_matrix_encoded)
```

The correlation matrix reveals some degree of correlation within the data. While multicollinearity is present, its impact on the overall model is minimal. Additionally, Lasso regression effectively mitigates these issues by performing variable selection and regularization.

# Lasso Regression

```{r}
#| label: lasso
x <- model.matrix(Income ~ Age + Education + Marital_Status + Occupation + Sex + Hours_PW + Nationality - 1, data = data)
y <- data$Income

cv_lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
print(paste("Best lambda for Lasso: ", cv_lasso$lambda.min))
plot(cv_lasso)

final_lasso_model <- glmnet(x, y, alpha = 1, lambda = cv_lasso$lambda.min)
coef(final_lasso_model)
```

Based on the analysis, we identified Age, Education, Marital Status (specifically "Married-civ-spouse"), Occupation (specifically "Exec-managerial"), and Hours Worked per Week as the most significant variables influencing income.

# Log-Odds and Odds Ratios {#sec-lod}

```{r}
#| label: Odds
mod.coed.logodds<- model_new %>%
                   summary() %>%
                   coef()
plot_model(model_new, show.values = TRUE, transform = NULL, 
           title = "Log-Odds", show.p = FALSE)
plot_model(model_new, show.values = TRUE, axis.lim = c(0, 10000), 
           title = "Odds Ratio", show.p = FALSE, transform = "exp")
```

The bar chart above illustrates the Log-Odds and Odds Ratios from model_new for the selected variables that have the strongest influence on income.

## Explanation of Variables' Impact on Income:

-   **Marital_StatusMarried-civ-spouse**: Being married to a civilian spouse has the highest Odds Ratio(11.88), indicating that individuals in this marital status are much more likely to earn over \$50k compared to others.

-   **OccupationExec-managerial**: Holding an executive or managerial position significantly increases the odds of earning more than \$50k(2.63).

-   **Education**: Higher levels of education are associated with a higher likelihood of earning more than \$50k, with the Odds Ratio being moderately high(1.42).

-   **Age**: Older individuals are slightly more likely to earn more than \$50k, although the impact is relatively smaller compared to other variables(1.03).

-   **Hours_PW**: Working more hours per week increases the odds of earning more than \$50k, showing a positive relationship(1.03).

-   **Nationality**: The coefficient for nationality in the chart is 1, indicating that the different values of this variable have no impact on the probability of the outcome.

-   **Sex**: The coefficient for gender is 0.89 (highlighted in red), which also indicates that the coefficient is not significant.

This chart highlights that **marital status**, **occupation**, and **education** have the most significant impact on income, whereas **sex** and **nationality** have a relatively minor effect.

# Probability continuous {#sec-pcs}

```{r}
#| label: Probability
p1 <- plot_model(model_new, type = "pred", terms="Age" ,title = "Age",
           axis.title = c("Age", "Prob. of income >50K"))
p2 <- plot_model(model_new, type = "pred", terms="Hours_PW" ,title = "Hours_PW",
           axis.title = c("Hours_PW", "Prob. of income >50K"))
grid.arrange(p1,p2,nrow=2)
```

As we metioned before, only age and hours worked are continuous variables in a meaningful sense. Therefore, we only plot these two variables.

# Conclusions {#sec-Conc}

In summary, the p-value, AIC, and Lasso regression all yield consistent results: gender and nationality have an insignificant impact on whether an individual earns more than $50K, while marital status and holding an executive position exert a stronger influence. Additionally, while factors such as education, age, and hours worked do play a role, they are not decisive in determining high income.

This finding is intriguing, as it suggests that marital status has a significant impact on income levels. However, the opposite conclusion seems more plausible: individuals with higher incomes tend to have more stable marital statuses. Moreover, the primary determinant of an employee's salary within a company appears to be their position. Without a managerial role, factors such as age, working hours, or education have little bearing on income.