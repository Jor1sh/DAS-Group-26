---
title: "Key Factors Influencing Income Level"
author: "Group26: JiaweiDeng QingHan PingchuanMA AoQiao XinWang"
number-sections: true
format:
  pdf: default
  html:
    embed-resources: true
    code-tools: true
editor_options: 
  chunk_output_type: console
execute:
  echo: true
  eval: true
  warning: false
  message: false
geometry: margin=1in,landscape
header-includes:
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \floatplacement{table}{H}
---

# Introductions

This report aims to identify the key factors based on the 1994 US Census data that influence whether an individual earns more than \$50k per year. The dataset includes a variety of socioeconomic variables, such as age, education level, marital status, occupation, sex, hours worked per week, and nationality. The response variable, Income, is a binary classification indicating whether an individual's income exceeds \$50k annually or not.

To address this task, we will utilize a Generalized Linear Model (GLM) to model the relationship between income and the various socioeconomic factors. The income variable will serve as the dependent variable, while the other variables will act as predictors.

# Libraries and reading {#sec-lr}

First of all we library all the package we may need.

```{r}
#| label: libraries
# Load the necessary package
library(ggplot2)
library(glmnet)
library(tidyverse)
library(gt)
library(patchwork)
library(gridExtra)
library(moderndive)
library(skimr)
```

Then we read the csv from the resource.

```{r}
#| label: data
# Read CSV data
data <- read.csv('dataset26.csv', na.strings = '?,')
```

# Data Tidying {#sec-dt}

Initially, we delete the null data, and treat only hours and age as numeric variables.

```{r}
#| label: tidy
data <- na.omit(data)
data <- data %>%
  mutate(across(2:ncol(data), ~ substr(.x, 1, nchar(.x) - 1)))
write.csv(data, 'cleaned_data.csv', row.names = FALSE)
```

```{r}
#| label: trans
data$Income <- ifelse(data$Income == "<=50", 0, 1)
data$Education <- as.factor(data$Education)
data$Marital_Status <- as.factor(data$Marital_Status)
data$Occupation <- as.factor(data$Occupation)
data$Sex <- as.factor(data$Sex)
data$Hours_PW <- as.numeric(data$Hours_PW)
data$Nationality <- as.factor(data$Nationality)

str(data)
```

# Full Modeling {#sec-mdl}

We fit the model, find that the coefficients are too many, it is really hard to see the vital variables.

```{r}
#| label: fullmodel
model <- glm(Income ~ Age + Education + Marital_Status + Occupation + Sex + Hours_PW + Nationality, 
             data = data, 
             family = binomial)
summary(model)
```

# P-value {#sec-pvl}

So we selected variables with p-values less than 0.05

```{r}
#| label: p-value
coef_table <- summary(model)$coefficients
coef_df <- as.data.frame(coef_table)

significant_vars <- coef_df[coef_df$`Pr(>|z|)` < 0.05, ]
significant_vars
```

As we can see, the ‘Age ’, ‘Education’, ‘Marital_Status’, ‘Occupation’ and ‘Hours_PW’ seem more important in this model.

# Data wrangling

On the basis of stepwise selection, we kept the variables ‘Age ’, ‘Education’, ‘Marital_Status’, ‘Occupation’, ‘Hours_PW’. Also after observing the results of the p-value selection, we turned education and nationality into ordered numerical variables. And we combined the other non-significant categories in ‘Marital_Status’ into one category, ‘Other’, and retained only the only significant category, ‘Married-civ-spouse’, and set ‘Other’ as the base group, i.e., whether the person was married to a civilian spouse. We did the same for ‘Occupation’, retaining only the ‘Exec-managerial’ category, i.e., whether the person was an Executive or Managerial.

```{r}
#| label: Data wrangling

# Order education level
edu_levels <- c(
  "Preschool", "1st-4th", "5th-6th", "7th-8th", "9th", "10th", 
  "11th", "12th", "HS-grad", "Some-college", "Assoc-acdm", 
  "Assoc-voc", "Bachelors", "Masters", "Prof-school", "Doctorate"
)
data$Education <- factor(data$Education, levels = edu_levels, ordered = TRUE)
data$Education <- as.numeric(data$Education)

# Order nationality level
data$Nationality <- as.factor(data$Nationality)
data$Nationality <- as.numeric(data$Nationality)

# Merge Occupation
levels(data$Occupation) <- ifelse(levels(data$Occupation) %in% c("Exec-managerial"), 
                                      levels(data$Occupation), "Other")
data$Occupation <- factor(data$Occupation)
data$Occupation <- relevel(data$Occupation, ref = "Other") # Set “Other” as the base group

# Merge Marital Status
levels(data$Marital_Status) <- ifelse(levels(data$Marital_Status) %in% c("Married-civ-spouse"), 
                                      levels(data$Marital_Status), "Other")
data$Marital_Status <- factor(data$Marital_Status)
data$Marital_Status <- relevel(data$Marital_Status, ref = "Other") # Set “Other” as the base group

model_new <- glm(Income ~ Age + Education + Marital_Status + Occupation + Sex + Hours_PW + Nationality, 
             data = data, 
             family = binomial)
summary(model_new)
```

The model looks more concise, and the results of variable filtering are as expected from the first time.

# Stepwise {#sec-stp}

```{r}
#| label: Stepwise
stepwise_model <- step(model_new, direction = "both", trace = 0)
summary(stepwise_model)

stepwise_aic <- AIC(stepwise_model)
print(paste("Stepwise AIC: ", stepwise_aic))
```

This shows that the data also performs much better in AIC.

# Data Correlation {#sec-dcr}

```{r}
#| label: cor
num_data <- data[, sapply(data, is.numeric)]
cor_matrix <- cor(num_data)
print(cor_matrix)

data_encoded <- model.matrix(~ Marital_Status + Occupation + Sex- 1, data = data)
cor_matrix_encoded <- cor(data_encoded)
print(cor_matrix_encoded)
```

The correlation matrix indicates that the data exhibits some level of correlation. Although there is multicollinearity, it has little impact on the overall model. Lasso regression effectively handles these issues.

# Lasso Regression

```{r}
#| label: lasso
x <- model.matrix(Income ~ Age + Education + Marital_Status + Occupation + Sex + Hours_PW + Nationality - 1, data = data)
y <- data$Income

cv_lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
print(paste("Best lambda for Lasso: ", cv_lasso$lambda.min))
plot(cv_lasso)

final_lasso_model <- glmnet(x, y, alpha = 1, lambda = cv_lasso$lambda.min)
coef(final_lasso_model)
```

Based on the above, we selected age, education, marital status as "Married-civ-spouse," occupation as "Exec-managerial," and hours_pw as the most significant variables influencing income.

# Data Visualization {#sec-dv}

```{r}
#| label: Visual
# Extract coefficients from the model_new
coefnew_df <- as.data.frame(summary(model_new)$coefficients)
coefnew_df$Variable <- rownames(coefnew_df)
coefnew_df <- coefnew_df[coefnew_df$`Pr(>|z|)` < 0.05, ]
coefnew_df$Odds_Ratio <- exp(coefnew_df$Estimate)

ggplot(coefnew_df, aes(x = reorder(Variable, Estimate), y = Estimate)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_errorbar(aes(ymin = Estimate - `Std. Error`, ymax = Estimate + `Std. Error`), width = 0.2) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Log-Odds of Significant Variables",
       x = "Variables",
       y = "Log-Odds (Coefficient)")

ggplot(coefnew_df, aes(x = reorder(Variable, Odds_Ratio), y = Odds_Ratio)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_errorbar(aes(ymin = exp(Estimate - `Std. Error`), ymax = exp(Estimate + `Std. Error`)), width = 0.2) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Odds Ratios from model_new",
       x = "Variables",
       y = "Odds Ratio")
```

The bar chart above displays the Log-Odds and Odds Ratios from model_new for the selected variables that most significantly influence income.

### Explanation of Variables' Impact on Income:

-   **Marital_StatusMarried-civ-spouse**: Being married to a civilian spouse has the highest Odds Ratio, indicating that individuals in this marital status are much more likely to earn over \$50k compared to others.

-   **OccupationExec-managerial**: Holding an executive or managerial position significantly increases the odds of earning more than \$50k.

-   **Education**: Higher levels of education are associated with a higher likelihood of earning more than \$50k, with the Odds Ratio being moderately high.

-   **Age**: Older individuals are slightly more likely to earn more than \$50k, although the impact is relatively smaller compared to other variables.

-   **Hours_PW**: Working more hours per week increases the odds of earning more than \$50k, showing a positive relationship.

-   **(Intercept)**: The baseline value without the influence of the variables indicates the odds of earning over \$50k for individuals who do not meet the conditions of the significant variables.

This chart highlights that **marital status**, **occupation**, and **education** have the most significant impact on income.

# Conclusions {#sec-Conc}
